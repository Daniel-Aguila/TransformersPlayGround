{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Jake, Thomas, TJ and I are going to Canada to play video games, get some time off and work on my business to get in shape,\" he told ESPN. \"For the first few days we\\'re going to be working through it and try'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"Jake, Thomas, TJ and I are going to Canada to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Jehdi went on a really good date with a guy, so ikat didn't really mind him. He was like 'this is for my friend'. But this day I'll be here in 3 weeks, to go all the way to\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"Jehdi went on a really good date with a guy, so \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'My dog started talking to me, when I opened fire, the black and white thing began to go, and she said, \"What\\'s your name?\" and then said, \"What\\'s your face?\" and it was like four people are running off'},\n",
       " {'generated_text': \"My dog started talking to me, when he finally came down and we started talking in Spanish - but we only really looked at, which meant that he would not hear the sound, so he gave me a really long speech, and I didn't see\"}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\",model=\"distilgpt2\")\n",
    "generator(\"My dog started talking to me, when\", max_length=50,num_return_sequences=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Playing Apex Legends is fun but gives me great anxiety, League of Legends is better',\n",
       " 'labels': ['video game', 'business', 'disaster'],\n",
       " 'scores': [0.9857428669929504, 0.009487814269959927, 0.0047692544758319855]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"Playing Apex Legends is fun but gives me great anxiety, League of Legends is better\",\n",
    "    candidate_labels=[\"video game\", \"disaster\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> We can see how there is Bias in data, even if specific data used to train the model has been select instead of just grabbing whatever.\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can lead to sexist, racist, homophobic and other cases of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carpenter', 'lawyer', 'farmer', 'businessman', 'doctor']\n"
     ]
    }
   ],
   "source": [
    "unmask = pipeline('fill-mask', model = 'bert-base-uncased')\n",
    "result = unmask(\"This man works as a [MASK].\")\n",
    "print([r['token_str'] for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nurse', 'maid', 'teacher', 'waitress', 'prostitute']\n"
     ]
    }
   ],
   "source": [
    "result = unmask(\"This woman works as a [MASK].\")\n",
    "print([r['token_str'] for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': \"  We hold the E.C. We welcome the tax again and our father John. I need some type of self-starring. She keeps sending me so. So I need any of your songs on the Joe's. I'm popping lies in my city. Let's pick you. Take some seats on nobody let's see. I don't sorry. I'll be let some Racers take some sex on somebody else . I'm a sadder than a street. Oh, I put in your energy. Give you all to me. Take your dust and be free .\",\n",
       " 'labels': ['Melancholy',\n",
       "  'Reflection',\n",
       "  'Empowerment',\n",
       "  'Excitement',\n",
       "  'Peace',\n",
       "  'Hope',\n",
       "  'Romance',\n",
       "  'Nostalgia',\n",
       "  'Euphoria',\n",
       "  'Happiness'],\n",
       " 'scores': [0.4646800756454468,\n",
       "  0.14523352682590485,\n",
       "  0.12987686693668365,\n",
       "  0.05534861609339714,\n",
       "  0.04344089329242706,\n",
       "  0.039770565927028656,\n",
       "  0.03798215091228485,\n",
       "  0.03764423355460167,\n",
       "  0.026318510994315147,\n",
       "  0.019704477861523628]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"  We hold the E.C. We welcome the tax again and our father John. I need some type of self-starring. She keeps sending me so. So I need any of your songs on the Joe's. I'm popping lies in my city. Let's pick you. Take some seats on nobody let's see. I don't sorry. I'll be let some Racers take some sex on somebody else . I'm a sadder than a street. Oh, I put in your energy. Give you all to me. Take your dust and be free .\",\n",
    "    candidate_labels=[\"Romance\", \"Melancholy\", \"Happiness\",\"Empowerment\",\"Nostalgia\",\"Peace\",\"Excitement\",\"Hope\",\"Reflection\",\"Euphoria\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 1.80k/1.80k [00:00<00:00, 4.32MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 1.22G/1.22G [01:12<00:00, 16.8MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 92.2kB/s]\n",
      "vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 7.11MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 13.6MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \" We hold the E.C. We welcome the tax again and our father John. I need some type of self-starring. She keeps sending me so. So I need any of your songs on the Joe's. I'm popping lies in my city. Let's pick you. Take some seats on nobody let's see. I don't sorry. I'll be let some Racers take some sex on somebody else . I'm a sadder than a street. Oh, I put in your energy. Give you all to me. Take your dust and be free .\"}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    We hold the E. We welcome the tax again and our father John. I'm the former, I'm the new love. I need some type of John. I need some type of self-starring. She keeps sending me so. I need some gun stuff there. She keeps sending me so. So I need some type of John. So I hit on my blow. I want to spit some time with it though. Come in so I can dig it up. Type a bitch who don't know who to fall. Falling in love. I'm my father John. Oh, she's letting us go. I need better to change. I'm a sadder than a street. I need any of your feet. That's the body of your feet. Come and fly with me. Oh, I put in your energy. Bitch, you know I'm scared. Give you all to me. Take your dust and be free. So we went all the way. We welcome the tax again and our father John. I never saw that. I never saw that. I need some type of gun. I don't have any type of self-starring. She keeps sending me so. I don't have any type of self-starring. She keeps sending me so. So I need any of your songs on the Joe's. I'm popping lies in my city. I need some type of lies, and let's pick you. Take some seats on nobody let's see. I don't sorry. I need someATHRICS Take someacje. I'll be let some Racers take some sex on somebody else. Take someHikke. Take some things onue,قةinori trader took some amb COLLA whatever Google eagle fentanyls. Every time I'm tired, I'm tired, I'm tired, I'm not allowed to sleep. We walk on, somewhere by the side. Guys, I'm buzzing at you, coming to you. Oh, I love you, my dear, my dear. Look at my son and I, I know I'm a creep. I spend in a jeep in the stow at sea free. Starting blow is a key.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 28.8k/28.8k [00:00<00:00, 36.5MB/s]\n",
      "Downloading metadata: 100%|██████████| 28.7k/28.7k [00:00<00:00, 40.0MB/s]\n",
      "Downloading readme: 100%|██████████| 27.9k/27.9k [00:00<00:00, 60.4MB/s]\n",
      "Downloading data: 6.22kB [00:00, 9.95MB/s]/3 [00:00<?, ?it/s]\n",
      "Downloading data: 1.05MB [00:00, 38.9MB/s]/3 [00:00<00:00,  3.53it/s]\n",
      "Downloading data: 441kB [00:00, 15.1MB/s]2/3 [00:00<00:00,  4.03it/s]\n",
      "Downloading data files: 100%|██████████| 3/3 [00:00<00:00,  4.13it/s]\n",
      "Generating train split: 100%|██████████| 3668/3668 [00:00<00:00, 32122.14 examples/s]\n",
      "Generating validation split: 100%|██████████| 408/408 [00:00<00:00, 7752.84 examples/s]\n",
      "Generating test split: 100%|██████████| 1725/1725 [00:00<00:00, 54476.81 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"glue\",\"mrpc\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset = raw_datasets[\"train\"]\n",
    "raw_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenized_sentences_1 = tokenizer(raw_datasets['train']['sentence1'])\n",
    "tokenized_sentences_2 = tokenizer(raw_datasets['train']['sentence2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example['sentence1'],example['sentence2'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3668/3668 [00:00<00:00, 8272.87 examples/s]\n",
      "Map: 100%|██████████| 408/408 [00:00<00:00, 7756.21 examples/s]\n",
      "Map: 100%|██████████| 1725/1725 [00:00<00:00, 8343.77 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function,batched=True)\n",
    "tokenized_datasets"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
